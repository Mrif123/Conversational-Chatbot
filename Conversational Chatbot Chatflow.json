{
  "nodes": [
    {
      "id": "conversationChain_0",
      "position": {
        "x": 1304.4815274908535,
        "y": -1955.2065199614021
      },
      "type": "customNode",
      "data": {
        "id": "conversationChain_0",
        "label": "Conversation Chain",
        "version": 3,
        "name": "conversationChain",
        "type": "ConversationChain",
        "baseClasses": [
          "ConversationChain",
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chat models specific conversational chain with memory",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "description": "If Chat Prompt Template is provided, this will be ignored",
            "additionalParams": true,
            "optional": true,
            "default": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
            "placeholder": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
            "id": "conversationChain_0-input-systemMessagePrompt-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationChain_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "id": "conversationChain_0-input-memory-BaseMemory",
            "display": true
          },
          {
            "label": "Chat Prompt Template",
            "name": "chatPromptTemplate",
            "type": "ChatPromptTemplate",
            "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
            "optional": true,
            "id": "conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationChain_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "model": "{{chatGoogleGenerativeAI_0.data.instance}}",
          "memory": "{{upstashRedisBackedChatMemory_0.data.instance}}",
          "chatPromptTemplate": "",
          "inputModeration": [],
          "systemMessagePrompt": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know."
        },
        "outputAnchors": [
          {
            "id": "conversationChain_0-output-conversationChain-ConversationChain|LLMChain|BaseChain|Runnable",
            "name": "conversationChain",
            "label": "ConversationChain",
            "description": "Chat models specific conversational chain with memory",
            "type": "ConversationChain | LLMChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 441,
      "selected": false,
      "positionAbsolute": {
        "x": 1304.4815274908535,
        "y": -1955.2065199614021
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_0",
      "position": {
        "x": -71.4822873980698,
        "y": -2016.6004115207656
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_0",
        "label": "ChatGoogleGenerativeAI",
        "version": 3.1,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-1.5-flash-latest",
            "id": "chatGoogleGenerativeAI_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-customModelName-string",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-maxOutputTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topP-number",
            "display": true
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topK-number",
            "display": true
          },
          {
            "label": "Safety Settings",
            "name": "safetySettings",
            "type": "array",
            "description": "Safety settings for the model. Refer to the <a href=\"https://ai.google.dev/gemini-api/docs/safety-settings\">official guide</a> on how to use Safety Settings",
            "array": [
              {
                "label": "Harm Category",
                "name": "harmCategory",
                "type": "options",
                "options": [
                  {
                    "label": "Dangerous",
                    "name": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "description": "Promotes, facilitates, or encourages harmful acts."
                  },
                  {
                    "label": "Harassment",
                    "name": "HARM_CATEGORY_HARASSMENT",
                    "description": "Negative or harmful comments targeting identity and/or protected attributes."
                  },
                  {
                    "label": "Hate Speech",
                    "name": "HARM_CATEGORY_HATE_SPEECH",
                    "description": "Content that is rude, disrespectful, or profane."
                  },
                  {
                    "label": "Sexually Explicit",
                    "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "description": "Contains references to sexual acts or other lewd content."
                  },
                  {
                    "label": "Civic Integrity",
                    "name": "HARM_CATEGORY_CIVIC_INTEGRITY",
                    "description": "Election-related queries."
                  }
                ]
              },
              {
                "label": "Harm Block Threshold",
                "name": "harmBlockThreshold",
                "type": "options",
                "options": [
                  {
                    "label": "None",
                    "name": "BLOCK_NONE",
                    "description": "Always show regardless of probability of unsafe content"
                  },
                  {
                    "label": "Only High",
                    "name": "BLOCK_ONLY_HIGH",
                    "description": "Block when high probability of unsafe content"
                  },
                  {
                    "label": "Medium and Above",
                    "name": "BLOCK_MEDIUM_AND_ABOVE",
                    "description": "Block when medium or high probability of unsafe content"
                  },
                  {
                    "label": "Low and Above",
                    "name": "BLOCK_LOW_AND_ABOVE",
                    "description": "Block when low, medium or high probability of unsafe content"
                  },
                  {
                    "label": "Threshold Unspecified (Default Threshold)",
                    "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
                    "description": "Threshold is unspecified, block using default threshold"
                  }
                ]
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-safetySettings-array",
            "display": true
          },
          {
            "label": "Base URL",
            "name": "baseUrl",
            "type": "string",
            "description": "Base URL for the API. Leave empty to use the default.",
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-baseUrl-string",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-allowImageUploads-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gemini-2.0-flash",
          "customModelName": "",
          "temperature": 0.9,
          "streaming": true,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "safetySettings": "",
          "baseUrl": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 676,
      "selected": false,
      "positionAbsolute": {
        "x": -71.4822873980698,
        "y": -2016.6004115207656
      },
      "dragging": false
    },
    {
      "id": "upstashRedisBackedChatMemory_0",
      "position": {
        "x": 748.2686549339799,
        "y": -1483.280300440763
      },
      "type": "customNode",
      "data": {
        "id": "upstashRedisBackedChatMemory_0",
        "label": "Upstash Redis-Backed Chat Memory",
        "version": 2,
        "name": "upstashRedisBackedChatMemory",
        "type": "UpstashRedisBackedChatMemory",
        "baseClasses": [
          "UpstashRedisBackedChatMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Summarizes the conversation and stores the memory in Upstash Redis server",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "description": "Configure password authentication on your upstash redis instance",
            "credentialNames": [
              "upstashRedisMemoryApi"
            ],
            "id": "upstashRedisBackedChatMemory_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Upstash Redis REST URL",
            "name": "baseURL",
            "type": "string",
            "placeholder": "https://<your-url>.upstash.io",
            "id": "upstashRedisBackedChatMemory_0-input-baseURL-string",
            "display": true
          },
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory/long-term-memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "additionalParams": true,
            "optional": true,
            "id": "upstashRedisBackedChatMemory_0-input-sessionId-string",
            "display": true
          },
          {
            "label": "Session Timeouts",
            "name": "sessionTTL",
            "type": "number",
            "description": "Seconds till a session expires. If not specified, the session will never expire.",
            "additionalParams": true,
            "optional": true,
            "id": "upstashRedisBackedChatMemory_0-input-sessionTTL-number",
            "display": true
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "upstashRedisBackedChatMemory_0-input-memoryKey-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "baseURL": "https://witty-shepherd-39500.upstash.io",
          "sessionId": "chat2",
          "sessionTTL": "",
          "memoryKey": ""
        },
        "outputAnchors": [
          {
            "id": "upstashRedisBackedChatMemory_0-output-upstashRedisBackedChatMemory-UpstashRedisBackedChatMemory|BaseChatMemory|BaseMemory",
            "name": "upstashRedisBackedChatMemory",
            "label": "UpstashRedisBackedChatMemory",
            "description": "Summarizes the conversation and stores the memory in Upstash Redis server",
            "type": "UpstashRedisBackedChatMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 433,
      "selected": false,
      "positionAbsolute": {
        "x": 748.2686549339799,
        "y": -1483.280300440763
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "chatGoogleGenerativeAI_0",
      "sourceHandle": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationChain_0",
      "targetHandle": "conversationChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-conversationChain_0-conversationChain_0-input-model-BaseChatModel"
    },
    {
      "source": "upstashRedisBackedChatMemory_0",
      "sourceHandle": "upstashRedisBackedChatMemory_0-output-upstashRedisBackedChatMemory-UpstashRedisBackedChatMemory|BaseChatMemory|BaseMemory",
      "target": "conversationChain_0",
      "targetHandle": "conversationChain_0-input-memory-BaseMemory",
      "type": "buttonedge",
      "id": "upstashRedisBackedChatMemory_0-upstashRedisBackedChatMemory_0-output-upstashRedisBackedChatMemory-UpstashRedisBackedChatMemory|BaseChatMemory|BaseMemory-conversationChain_0-conversationChain_0-input-memory-BaseMemory"
    }
  ]
}